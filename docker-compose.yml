# Docker Compose pour Qwen3-VL FastAPI Server
services:
  qwen-api:
    build:
      context: .
      dockerfile: Dockerfile
    image: qwen-fastapi:latest
    container_name: qwen-api-server
    
    # Configuration NVIDIA Runtime - OBLIGATOIRE pour GPU
    runtime: nvidia
    
    # Variables d'environnement
    environment:
      # Configuration API
      - API_PREFIX=${API_PREFIX:-}
      - ROOT_PATH=${ROOT_PATH:-}
      - HOST=0.0.0.0
      - PORT=8000
      - WORKERS=${WORKERS:-1}
      
      # Configuration modèle
      - MODEL_NAME=${MODEL_NAME:-Qwen/Qwen2-VL-7B-Instruct}
      - MAX_SEQ_LENGTH=${MAX_SEQ_LENGTH:-32768}
      - LOAD_IN_4BIT=${LOAD_IN_4BIT:-true}
      
      # Configuration GPU - OBLIGATOIRE pour le modèle
      - NVIDIA_VISIBLE_DEVICES=1
      - CUDA_VISIBLE_DEVICES=0
      
      # Configuration sécurité
      - CORS_ORIGINS=${CORS_ORIGINS:-*}
      - TRUSTED_HOSTS=${TRUSTED_HOSTS:-}
      
      # Hugging Face token (optionnel pour modèles privés)
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN:-}
    
    # Suppression du port mapping - accès via Traefik uniquement
    # ports:
    #   - "${HOST_PORT:-8000}:8000"
    
    # Volumes pour persistance et cache
    volumes:
      - ./models:/app/models
      - ./logs:/app/logs
      - ./cache:/root/.cache
    
    # Configuration mémoire optimisée pour Qwen2-VL-2B
    deploy:
      resources:
        limits:
          memory: 16G  # Nécessaire pour le modèle 2.2B paramètres
          cpus: '4'
    
    # Santé et redémarrage
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000${API_PREFIX:-}/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 2m  # Temps pour le chargement du modèle
    
    restart: always
    
    # Réseau Ansible
    networks:
      - ansible
    
    # Logs
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "3"

networks:
  ansible:
    external: true
    name: ansible
